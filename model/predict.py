import torch
import torch.nn as nn
import jieba
import pandas as pd
import os
from collections import Counter

# ==========================================
# 1. å¿…é¡»ä¿æŒå’Œè®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´çš„é…ç½®
# ==========================================
MAX_LEN = 50
EMBEDDING_DIM = 100
HIDDEN_DIM = 128

# ==========================================
# 2. å®šä¹‰æ¨¡å‹ (å¿…é¡»å’Œè®­ç»ƒä»£ç é‡Œçš„é•¿å¾—ä¸€æ¨¡ä¸€æ ·)
# ==========================================
class SentimentLSTM(nn.Module):
    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim=2):
        super(SentimentLSTM, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)
        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)
        
    def forward(self, text):
        embedded = self.embedding(text) 
        output, (hidden, cell) = self.lstm(embedded)
        final_hidden = hidden[-1] 
        return self.fc(final_hidden)

# ==========================================
# 3. æ ¸å¿ƒåŠŸèƒ½ï¼šåŠ è½½æ¨¡å‹å¹¶é¢„æµ‹
# ==========================================
def predict_sentiment():
    print("â³ æ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿï¼Œè¯·ç¨å€™...")
    
    # --- ç¬¬ä¸€æ­¥ï¼šé‡å»ºè¯å…¸ (ä¸ºäº†ä¿è¯å’Œè®­ç»ƒæ—¶å¯¹åº”çš„æ•°å­—ä¸€æ ·) ---
    # è¿™é‡Œæˆ‘ä»¬å¿«é€Ÿé‡è¯»ä¸€éæ•°æ®æ¥ç”Ÿæˆè¯å…¸
    current_dir = os.path.dirname(os.path.abspath(__file__))
    data_path = os.path.join(current_dir, '..', 'data', 'ChnSentiCorp_htl_all.csv')
    df = pd.read_csv(data_path).dropna(subset=['review'])
    texts = df['review'].astype(str).tolist()
    
    all_words = []
    for text in texts:
        all_words.extend(jieba.lcut(text))
    
    vocab = {"<PAD>": 0, "<UNK>": 1}
    for word, _ in Counter(all_words).most_common(5000):
        vocab[word] = len(vocab)
    print("âœ… è¯å…¸åŠ è½½å®Œæ¯•ï¼")

    # --- ç¬¬äºŒæ­¥ï¼šåŠ è½½æ¨¡å‹ ---
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = SentimentLSTM(len(vocab), EMBEDDING_DIM, HIDDEN_DIM)
    
    # åŠ è½½è®­ç»ƒå¥½çš„å‚æ•°
    model_path = os.path.join(current_dir, 'sentiment_model.pth')
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location=device))
        print("âœ… æˆåŠŸåŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼")
    else:
        print("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ sentiment_model.pth")
        return

    model.eval() # å¼€å¯è¯„ä¼°æ¨¡å¼

    # --- ç¬¬ä¸‰æ­¥ï¼šå¾ªç¯è®©ç”¨æˆ·è¾“å…¥ ---
    print("\n" + "="*40)
    print("ğŸ¤– æƒ…æ„Ÿåˆ†ææœºå™¨äººå·²å°±ç»ªï¼")
    print("è¾“å…¥è¯„è®ºåå›è½¦ï¼Œè¾“å…¥ 'q' é€€å‡º")
    print("="*40)

    while True:
        text = input("\nè¯·è¾“å…¥æµ‹è¯•è¯„è®º: ")
        if text.lower() == 'q':
            break
        
        if not text.strip():
            continue

        # é¢„å¤„ç†è¾“å…¥
        words = jieba.lcut(text)
        ids = [vocab.get(w, 1) for w in words]
        
        # å¡«å……/æˆªæ–­
        if len(ids) > MAX_LEN:
            ids = ids[:MAX_LEN]
        else:
            ids = ids + [0] * (MAX_LEN - len(ids))
            
        # è½¬ä¸º Tensor å¹¶é¢„æµ‹
        tensor_input = torch.tensor([ids], dtype=torch.long)
        with torch.no_grad():
            output = model(tensor_input)
            probability = torch.nn.functional.softmax(output, dim=1)
            # è·å–é¢„æµ‹ç»“æœ (0æ˜¯å·®è¯„, 1æ˜¯å¥½è¯„)
            pred_class = torch.argmax(probability).item()
            confidence = probability[0][pred_class].item()

        # æ‰“å°ç»“æœ
        if pred_class == 1:
            print(f"ğŸ‘‰ é¢„æµ‹ç»“æœï¼šã€å¥½è¯„ ğŸ˜Šã€‘ (ç½®ä¿¡åº¦: {confidence:.2%})")
        else:
            print(f"ğŸ‘‰ é¢„æµ‹ç»“æœï¼šã€å·®è¯„ ğŸ˜¡ã€‘ (ç½®ä¿¡åº¦: {confidence:.2%})")

if __name__ == "__main__":
    predict_sentiment()