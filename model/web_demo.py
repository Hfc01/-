import streamlit as st
import torch
import torch.nn as nn
import jieba
import pandas as pd
import os
from collections import Counter

# ==========================================
# 1. æ ¸å¿ƒé…ç½® (å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´)
# ==========================================
MAX_LEN = 50
EMBEDDING_DIM = 100
HIDDEN_DIM = 128

# ==========================================
# 2. å®šä¹‰æ¨¡å‹æ¶æ„
# ==========================================
class SentimentLSTM(nn.Module):
    def __init__(self, vocab_size, embed_dim, hidden_dim, output_dim=2):
        super(SentimentLSTM, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)
        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)
        
    def forward(self, text):
        embedded = self.embedding(text) 
        output, (hidden, cell) = self.lstm(embedded)
        final_hidden = hidden[-1] 
        return self.fc(final_hidden)

# ==========================================
# 3. åŠ è½½èµ„æº (ä½¿ç”¨ç¼“å­˜ï¼Œç½‘é¡µä¸å¡é¡¿)
# ==========================================
@st.cache_resource
def load_resources():
    # --- A. è·å–è·¯å¾„ ---
    current_dir = os.path.dirname(os.path.abspath(__file__))
    data_path = os.path.join(current_dir, '..', 'data', 'ChnSentiCorp_htl_all.csv')
    model_path = os.path.join(current_dir, 'sentiment_model.pth')

    # --- B. é‡å»ºè¯å…¸ ---
    if not os.path.exists(data_path):
        return None, None, "æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ data æ–‡ä»¶å¤¹ï¼"
    
    df = pd.read_csv(data_path).dropna(subset=['review'])
    texts = df['review'].astype(str).tolist()
    all_words = []
    for text in texts:
        all_words.extend(jieba.lcut(text))
    
    vocab = {"<PAD>": 0, "<UNK>": 1}
    for word, _ in Counter(all_words).most_common(5000):
        vocab[word] = len(vocab)

    # --- C. åŠ è½½æ¨¡å‹ ---
    if not os.path.exists(model_path):
        return None, None, "æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œè¯·ç¡®è®¤ sentiment_model.pth åœ¨ model æ–‡ä»¶å¤¹é‡Œï¼"

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = SentimentLSTM(len(vocab), EMBEDDING_DIM, HIDDEN_DIM)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    
    return model, vocab, "SUCCESS"

# ==========================================
# 4. ç½‘é¡µç•Œé¢ä¸»ç¨‹åº
# ==========================================
def main():
    # è®¾ç½®ç½‘é¡µæ ‡é¢˜
    st.set_page_config(page_title="ç”µå•†è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ", page_icon="ğŸ›’")
    
    st.title("ğŸ›’ åŸºäºæ·±åº¦å­¦ä¹ çš„ç”µå•†è¯„è®ºæƒ…æ„Ÿåˆ†æ")
    st.markdown("è¿™æ˜¯ä½ çš„æ¯•ä¸šè®¾è®¡æ¼”ç¤ºç³»ç»Ÿã€‚è¾“å…¥ä¸€æ®µè¯„è®ºï¼ŒAI å°†è‡ªåŠ¨è¯†åˆ«æ˜¯å¥½è¯„è¿˜æ˜¯å·®è¯„ã€‚")

    # åŠ è½½æ¨¡å‹ (æ˜¾ç¤ºåŠ è½½çŠ¶æ€)
    with st.spinner('æ­£åœ¨åˆå§‹åŒ– AI å¤§è„‘...'):
        model, vocab, status = load_resources()

    if status != "SUCCESS":
        st.error(status)
        return

    # å·¦è¾¹è¾“å…¥ï¼Œå³è¾¹å±•ç¤º
    col1, col2 = st.columns([2, 1])

    with col1:
        # è¾“å…¥æ¡†
        user_input = st.text_area("åœ¨æ­¤è¾“å…¥è¯„è®ºå†…å®¹ï¼š", height=150, placeholder="ä¾‹å¦‚ï¼šä¸œè¥¿å¾ˆå¥½ï¼Œç‰©æµå¾ˆå¿«ï¼Œä¸‹æ¬¡è¿˜æ¥ï¼")
        predict_btn = st.button("å¼€å§‹åˆ†æ ğŸš€", type="primary")

    with col2:
        st.write("---")
        if predict_btn and user_input:
            if not user_input.strip():
                st.warning("è¯·è¾“å…¥æœ‰æ•ˆå†…å®¹ï¼")
            else:
                # --- é¢„æµ‹é€»è¾‘ ---
                words = jieba.lcut(user_input)
                ids = [vocab.get(w, 1) for w in words]
                if len(ids) > MAX_LEN:
                    ids = ids[:MAX_LEN]
                else:
                    ids = ids + [0] * (MAX_LEN - len(ids))
                
                tensor_input = torch.tensor([ids], dtype=torch.long)
                
                with torch.no_grad():
                    output = model(tensor_input)
                    probability = torch.nn.functional.softmax(output, dim=1)
                    pred_class = torch.argmax(probability).item()
                    confidence = probability[0][pred_class].item()

                # --- ç»“æœå±•ç¤º ---
                if pred_class == 1:
                    st.success("## ğŸ˜Š åˆ†æç»“æœï¼šå¥½è¯„")
                    st.metric("ç½®ä¿¡åº¦ (AIæœ‰å¤šç¡®å®š)", f"{confidence:.2%}")
                    st.balloons() # æ”¾ä¸ªæ°”çƒåº†ç¥ä¸€ä¸‹
                else:
                    st.error("## ğŸ˜¡ åˆ†æç»“æœï¼šå·®è¯„")
                    st.metric("ç½®ä¿¡åº¦ (AIæœ‰å¤šç¡®å®š)", f"{confidence:.2%}")



# ==========================================
# 4. ç½‘é¡µç•Œé¢ä¸»ç¨‹åº 
# ==========================================
def main():
    st.set_page_config(page_title="ç”µå•†è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ", page_icon="ğŸ›’", layout="wide")
    
    st.title("ğŸ›’ åŸºäº LSTM çš„ç”µå•†è¯„è®ºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ")
    
    # åŠ è½½æ¨¡å‹
    with st.spinner('æ­£åœ¨åˆå§‹åŒ– AI å¤§è„‘...'):
        model, vocab, status = load_resources()

    if status != "SUCCESS":
        st.error(status)
        return

    # --- ä¾§è¾¹æ ï¼šåŠŸèƒ½é€‰æ‹© ---
    st.sidebar.title("åŠŸèƒ½èœå•")
    app_mode = st.sidebar.radio("è¯·é€‰æ‹©æ¨¡å¼", ["å•æ¡æµ‹è¯• (æ¼”ç¤ºç”¨)", "æ‰¹é‡åˆ†æ (å®æˆ˜ç”¨)"])

    # ===================================
    # æ¨¡å¼ä¸€ï¼šå•æ¡æµ‹è¯• 
    # ===================================
    if app_mode == "å•æ¡æµ‹è¯• (æ¼”ç¤ºç”¨)":
        st.header("ğŸ‘¤ å•æ¡è¯„è®ºå®æ—¶åˆ†æ")
        st.markdown("è¿™é‡Œæ¨¡æ‹Ÿçš„æ˜¯ **å®¢æœäººå‘˜** æ”¶åˆ°ä¸€æ¡æŠ•è¯‰æ—¶çš„åœºæ™¯ã€‚")
        
        col1, col2 = st.columns([2, 1])
        with col1:
            user_input = st.text_area("è¾“å…¥è¯„è®ºå†…å®¹ï¼š", height=150, placeholder="ä¾‹å¦‚ï¼šç‰©æµå¤ªæ…¢äº†ï¼ŒåŒ…è£…ä¹Ÿç ´äº†ï¼")
            predict_btn = st.button("å¼€å§‹åˆ†æ ğŸš€", type="primary")
        
        with col2:
            st.write("---")
            if predict_btn and user_input:
                if not user_input.strip():
                    st.warning("è¯·è¾“å…¥æœ‰æ•ˆå†…å®¹ï¼")
                else:
                    # é¢„æµ‹é€»è¾‘
                    words = jieba.lcut(user_input)
                    ids = [vocab.get(w, 1) for w in words]
                    if len(ids) > MAX_LEN: ids = ids[:MAX_LEN]
                    else: ids = ids + [0] * (MAX_LEN - len(ids))
                    
                    tensor_input = torch.tensor([ids], dtype=torch.long)
                    with torch.no_grad():
                        output = model(tensor_input)
                        prob = torch.nn.functional.softmax(output, dim=1)
                        pred_class = torch.argmax(prob).item()
                        conf = prob[0][pred_class].item()

                    if pred_class == 1:
                        st.success("## ğŸ˜Š å¥½è¯„")
                        st.metric("ç½®ä¿¡åº¦", f"{conf:.2%}")
                    else:
                        st.error("## ğŸ˜¡ å·®è¯„")
                        st.metric("ç½®ä¿¡åº¦", f"{conf:.2%}")

   
    # æ¨¡å¼äºŒï¼šæ‰¹é‡åˆ†æ 
    
    elif app_mode == "æ‰¹é‡åˆ†æ (å®æˆ˜ç”¨)":
        st.header("ğŸ“Š æµ·é‡æ•°æ®è‡ªåŠ¨åŒ–å¤„ç†")
        st.markdown("è¿™é‡Œæ¨¡æ‹Ÿçš„æ˜¯ **åå°ç³»ç»Ÿ** è‡ªåŠ¨å¤„ç†æˆåƒä¸Šä¸‡æ¡å†å²è¯„è®ºçš„åœºæ™¯ã€‚")
        
        uploaded_file = st.file_uploader("ä¸Šä¼  CSV æ–‡ä»¶ (éœ€åŒ…å« 'review' åˆ—)", type=["csv"])
        
        if uploaded_file is not None:
            df = pd.read_csv(uploaded_file)
            st.write(f"âœ… æˆåŠŸè¯»å–æ–‡ä»¶ï¼Œå…± {len(df)} æ¡æ•°æ®ã€‚å‰ 5 æ¡é¢„è§ˆï¼š")
            st.dataframe(df.head())
            
            if 'review' not in df.columns:
                st.error("âŒ æ–‡ä»¶é‡Œå¿…é¡»æœ‰ä¸€åˆ—å« 'review' å“¦ï¼")
            else:
                if st.button("å¼€å§‹æ‰¹é‡åˆ†æ (å¯èƒ½ä¼šèŠ±ä¸€ç‚¹æ—¶é—´)"):
                    # è¿›åº¦æ¡
                    progress_bar = st.progress(0)
                    results = []
                    probs = []
                    
                    # æ‰¹é‡é¢„æµ‹
                    total = len(df)
                    # ä¸ºäº†æ¼”ç¤ºä¸å¡é¡¿ï¼Œæˆ‘ä»¬åªå–å‰100æ¡æˆ–è€…å…¨éƒ¨ (å¦‚æœç”µè„‘å¿«çš„è¯)
                    # è¿™é‡Œæ¼”ç¤ºå¤„ç†å…¨éƒ¨æ•°æ®
                    texts = df['review'].astype(str).tolist()
                    
                    input_ids = []
                    for text in texts:
                        words = jieba.lcut(text)
                        ids = [vocab.get(w, 1) for w in words]
                        if len(ids) > MAX_LEN: ids = ids[:MAX_LEN]
                        else: ids = ids + [0] * (MAX_LEN - len(ids))
                        input_ids.append(ids)
                    
                    # è½¬ Tensor
                    tensor_input = torch.tensor(input_ids, dtype=torch.long)
                    
                    # é¢„æµ‹
                    with torch.no_grad():
                        outputs = model(tensor_input)
                        probabilities = torch.nn.functional.softmax(outputs, dim=1)
                        predictions = torch.argmax(probabilities, dim=1).tolist()
                        max_probs = torch.max(probabilities, dim=1).values.tolist()
                    
                    # æŠŠç»“æœå†™å›è¡¨æ ¼
                    df['é¢„æµ‹ç»“æœ'] = ['å¥½è¯„' if p==1 else 'å·®è¯„' for p in predictions]
                    df['ç½®ä¿¡åº¦'] = [f"{p:.2%}" for p in max_probs]
                    
                    progress_bar.progress(100)
                    st.success("ğŸ‰ åˆ†æå®Œæˆï¼")
                    
                    # å±•ç¤ºç»Ÿè®¡å›¾è¡¨
                    st.subheader("åˆ†ææŠ¥å‘Š")
                    count_data = df['é¢„æµ‹ç»“æœ'].value_counts()
                    st.bar_chart(count_data)
                    
                    st.write("è¯¦ç»†ç»“æœé¢„è§ˆï¼š")
                    st.dataframe(df[['review', 'é¢„æµ‹ç»“æœ', 'ç½®ä¿¡åº¦']])

if __name__ == "__main__":
    main()